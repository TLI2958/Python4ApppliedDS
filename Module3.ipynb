{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centrality\n",
    "__Uses__\n",
    "- Influential nodes in a social network\n",
    "- Nodes that disseminate information to many nodes or prevent epidemics\n",
    "- Hubs in a transportation network\n",
    "- Important pages on the Web\n",
    "- Nodes that prevent the network from breaking up\n",
    "\n",
    "__Measures__\n",
    "- Degree Centrality\n",
    "    - important nodes have many connections, i.e., number of neighbors\n",
    "    - Undirected networks: use degree\n",
    "        - $C_{deg}(v) = \\frac{d_{v}}{{|N|-1}}$, Where N is the set of nodes in the network and $d_{v}$ is the degree of node v\n",
    "    - Directed networksL use in-degree or out-degree\n",
    "        - $C_{deg}^{in} = \\frac{d_{v}^{in}}{{|N|-1}}$ \n",
    "        - $C_{deg}^{out} = \\frac{d_{v}^{out}}{{|N|-1}}$ \n",
    "<br></br>\n",
    "- Closeness Centrality\n",
    "    - important nodes are close to other nodes\n",
    "    - Formula:\n",
    "        - $C_{close}(v) = \\frac{|N|-1}{{\\sum_{u\\in N!(v)}^{d(v,u)}}}$\n",
    "        - closeCent = nx.closeness_centrality(G)\n",
    "    - How to reach the closeness centrality of a node when it cannot reach all other nodes?\n",
    "        - Option I: Consider only nodes that node L can reach\n",
    "        - Option II: Consider only nodes that node L can reach, but normalize by the fraction of nodes L can reach\n",
    "            - $C_{close(L)} = \\begin{pmatrix}|\\frac{R(L)}{{N-1}}|\\end{pmatrix}\\frac{|R(L)|}{{\\sum_{u\\in R(L)}^{d(L,u)}}}$\n",
    "            - closeCent = nx.closeness_centrality(G,normalized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5151515151515151"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Degree Centrality\n",
    "# Undirected Networks\n",
    "import networkx as nx\n",
    "G = nx.karate_club_graph()\n",
    "G = nx.convert_node_labels_to_integers(G,first_label = 1)\n",
    "degCent = nx.degree_centrality(G)\n",
    "degCent[34] # 17/33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directed Networks\n",
    "- indegCent = nx.in_degree_centrality(G)\n",
    "- indegCent[1]\n",
    "- outdegCent = nx.out_degree_centrality(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness Centrality\n",
    "__Assumption__\n",
    "- Important nodes connect other nodes\n",
    "<br></br>\n",
    "\n",
    "__Formula__\n",
    "- $C_{btw}(v) = \\sum_{s,t\\in N}\\frac{\\sigma_{s,t}(v)}{{\\sigma_{s,t}}}$ \n",
    "- sum of shortest paths between nodes $s$ and $t$ that pass through node $v$\n",
    "- over number of shortest paths between nodes $s$ and $t$   \n",
    "    \n",
    "__Endpoint__\n",
    "- we can either include or exclude node $v$ as node $s$ and $t$ in the computaton of $C_{btw}(v)$\n",
    "\n",
    "__ Unconnected?__\n",
    "- e.g., Node $D$ can not be reached by any other node\n",
    "- Only considering nodes $s,t$ having at least one shortest path inbetween \n",
    "\n",
    "__Normalization__\n",
    "- Betweenness centrality values will be larger in graphs with many nodes. \n",
    "- To control for this, we divide centrality values by the number of pairs of nodes in the graph(excluding $v$)\n",
    "    - $\\frac{1}{{2}}(|N|-1)(|N|-2)$ in undirected graphs\n",
    "    - $(|N|-1)(|N|-2)$ in directed graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.4376352813852815),\n",
       " (34, 0.30407497594997596),\n",
       " (33, 0.14524711399711404),\n",
       " (3, 0.14365680615680615),\n",
       " (32, 0.13827561327561327)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btwnCent = nx.betweenness_centrality(G,normalized = True, endpoints = False)\n",
    "import operator\n",
    "sorted(btwnCent.items(),key = operator.itemgetter(1),reverse = True)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Complexity__\n",
    "- Computationally expensive\n",
    "__Approximation__\n",
    "- using a sample of nodes\n",
    "    - like stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.484459626022126),\n",
       " (34, 0.25483390452140453),\n",
       " (33, 0.18650733525733526),\n",
       " (32, 0.10650042087542086),\n",
       " (3, 0.10410353535353536)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btwnCent_approx = nx.betweenness_centrality(G,normalized=True,endpoints=False,k=10) # using 10 rather than all the nodes\n",
    "sorted(btwnCent_approx.items(),key = operator.itemgetter(1),reverse=True)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Subsets__\n",
    "- most important nodes between the source & target node sets\n",
    "- $s$ *always* from source nodes, $t$ from target nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.04899515993265994),\n",
       " (34, 0.028807419432419434),\n",
       " (3, 0.018368205868205867),\n",
       " (33, 0.01664712602212602),\n",
       " (9, 0.014519450456950456)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btwnCent_subset = nx.betweenness_centrality_subset(G,[34,33,21,30,16,27,15,23,10],[1,4,13,11,6,12,17,7],normalized=True)\n",
    "sorted(btwnCent_subset.items(),key = operator.itemgetter(1),reverse=True)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Edges__\n",
    "- $C_{btw}(e) = \\sum_{s,t\\in N}\\frac{\\sigma_s,t(e)}{{\\sigma_{s,t}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 32), 0.12725999490705373),\n",
       " ((1, 7), 0.07813428401663695),\n",
       " ((1, 6), 0.07813428401663694),\n",
       " ((1, 3), 0.07778768072885717),\n",
       " ((1, 9), 0.07423959482783016)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btwnCent_edge = nx.edge_betweenness_centrality(G,normalized=True)\n",
    "sorted(btwnCent_edge.items(),key = operator.itemgetter(1),reverse = True)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 9), 0.01366536513595337),\n",
       " ((1, 32), 0.01366536513595337),\n",
       " ((14, 34), 0.012207509266332794),\n",
       " ((1, 3), 0.01211343123107829),\n",
       " ((1, 6), 0.012032085561497326)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btwnCent_edge_subset = nx.edge_betweenness_centrality_subset(G,[34,33,21,30,16,27,15,23,10],[1,4,13,11,6,12,17,7],normalized=True)\n",
    "sorted(btwnCent_edge_subset.items(),key = operator.itemgetter(1),reverse=True)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page Rank\n",
    "- Basic ideas: developed to measure the importance of webpages from the hyperlink network structure\n",
    "    - assign a score of importance to each node\n",
    "    - important nodes are those with many in-links from important pages\n",
    "    - mainly useful for directed networks\n",
    "- Steps\n",
    "    - $n =$ number of nodes in the network; $k=$ number of steps\n",
    "    - Assign all nodes a PageRank of $\\frac{1}{{n}}$\n",
    "    - Perform the __Basic PageRank Update Rule__ $k$ times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Page Rank\n",
    "__Basic PageRank Updata Rule__\n",
    "- Each node gives an equal share of its current PageRank to all the nodes it links to\n",
    "- Update the PR of the node $A$ by multiply $\\frac{C_{A}}{{C_{all}}}$, Where $C$ refers to all the projections out of $C$\n",
    "- Iterate until convergence, i.e., changing a little"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled PageRank \n",
    "__Random walk of k steps__\n",
    "- Choose a random node; Choose a random edge; To the next node; Repeat $k$ times\n",
    "- BPR refers to the probability of taking a random walk of $k$ steps and land on the specific node \n",
    "<br></br>\n",
    "\n",
    "__Damping Parameter $\\alpha$__\n",
    "\n",
    "- with probability $\\alpha$, choose an outgoing edge at random and follow it to the next node\n",
    "- with probability $1 - \\alpha$, choose a node at random at go to it\n",
    "- repeat $k$ times\n",
    "- avoid stucks on certain nodes\n",
    "- $\\alpha \\in [0.8,0.9]$ \n",
    "- works well for large network\n",
    "- $nx.pagerank(G,\\alpha = .8)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hubs and Authorities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Root\n",
    "    - set of highly relevant web pages - potential *authorities*\n",
    "        - pages containing the query string\n",
    "- Hubs\n",
    "    - Find all pages that link to a page in root: potential *hubs*\n",
    "\n",
    "- Base\n",
    "    - root nodes and any node that links to a node in root\n",
    "    - aka. Root + Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HITS Algorithm\n",
    "- Computing $k$ iterations of HITS algorithm to assign an *authority* score and *hub* score to each node\n",
    "- Assign each node an authority and hub score of 1\n",
    "- Apply __Authority Update Rule__: each node's <font color = 'red'> *authority*</font> score is the sum of <font color = 'red'>*hub*</font>  scores of each node that <font color = 'red'>*points to it*</font>\n",
    "- Apply __Hub Update Rule__: each node's <font color = 'red'> *hub*</font> score is the sum of <font color = 'red'>*authority*</font>  scores of each node that <font color = 'red'>*it points to*</font>\n",
    "- Normalize Authority and Hub scores: $auth(j) = \\frac{auth(j)}{{\\sum_{i\\in N}auth(i)}}$; same for Hub\n",
    "- Repeat $k$ times until convergence\n",
    "- $nx.hits(G)$ with two dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Centrality Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0.03333333333333333,\n",
       " 'B': 0.07777777777777777,\n",
       " 'C': 0.18888888888888888,\n",
       " 'D': 0.38888888888888884,\n",
       " 'E': 0.1111111111111111,\n",
       " 'F': 0.0,\n",
       " 'G': 0.3333333333333333}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "G.add_edges_from([('A','B'),\n",
    "                  ('A','C'),\n",
    "                  ('B','D'),\n",
    "                  ('C','D'),\n",
    "                  ('C','E'),\n",
    "                  ('D','E'),\n",
    "                  ('D','G'),\n",
    "                  ('E','G'),\n",
    "                  ('G','F')\n",
    "])\n",
    "nx.edge_betweenness_centrality(G,normalized = False)\n",
    "nx.betweenness_centrality(G,normalized = True, endpoints = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'A': 0.4,\n",
       "  'B': 0.2857142857142857,\n",
       "  'C': 0.02857142857142857,\n",
       "  'D': 0.2857142857142857},\n",
       " {'A': 0.06666666666666667,\n",
       "  'B': 0.26666666666666666,\n",
       "  'C': 0.6666666666666666,\n",
       "  'D': 0.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G2 = nx.DiGraph()\n",
    "G2.add_edges_from([('A','B'),\n",
    "                  ('B','C'),\n",
    "                  ('A','C'),\n",
    "                  ('C','A'),\n",
    "                   ('D','C'),\n",
    "                  ])\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "nx.hits(G2,max_iter=2,tol = 1,normalized=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
